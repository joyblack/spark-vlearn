2019-02-17 22:20:31,527   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:20:31,786   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:20:31,838   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:20:31,839   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:20:31,840   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:20:31,840   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:20:31,840   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:20:32,442   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 61886.
2019-02-17 22:20:32,460   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:20:32,475   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:20:32,477   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:20:32,477   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:20:32,487   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-b3522221-ae1e-476e-93a4-4b5759014da9
2019-02-17 22:20:32,506   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:20:32,518   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:20:32,585   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2146ms
2019-02-17 22:20:32,627   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:20:32,637   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2199ms
2019-02-17 22:20:32,652   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:20:32,653   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:20:32,668   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,669   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,669   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,670   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,670   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,670   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,671   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,671   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,672   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,672   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,672   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,673   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,673   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,674   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,674   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,674   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,675   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,675   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,675   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,676   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,680   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,681   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,682   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,682   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:20:32,683   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:20:32,759   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:20:32,797   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61900.
2019-02-17 22:20:32,798   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:61900
2019-02-17 22:20:32,799   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:20:32,825   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 61900, None)
2019-02-17 22:20:32,827   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:61900 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 61900, None)
2019-02-17 22:20:32,829   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 61900, None)
2019-02-17 22:20:32,830   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 61900, None)
2019-02-17 22:20:32,936   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:33,078   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:20:33,097   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:20:33,097   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:20:33,105   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:20:33,105   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:33,105   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:20:33,106   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:20:33,107   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:20:33,519   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:20:35,149   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 145.307933 ms
2019-02-17 22:20:35,179   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.582276 ms
2019-02-17 22:20:35,229   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:20:35,233   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:20:35,234   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:20:35,242   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:20:35,249   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:20:35,250   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:20:35,254   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:20:35,256   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:20:35,261   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:20:35,261   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:20:35,262   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-fcf3c255-8562-4504-ba53-54a965e48792
2019-02-17 22:26:13,558   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:26:13,830   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:26:13,881   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:26:13,883   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:26:13,883   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:26:13,884   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:26:13,884   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:26:14,490   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62314.
2019-02-17 22:26:14,508   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:26:14,524   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:26:14,526   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:26:14,527   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:26:14,536   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-e5c1b8cd-f883-44ac-9b3f-b9b23aa9f190
2019-02-17 22:26:14,556   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:26:14,568   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:26:14,638   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2228ms
2019-02-17 22:26:14,679   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:26:14,688   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2279ms
2019-02-17 22:26:14,703   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:26:14,704   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:26:14,718   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,719   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,719   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,720   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,720   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,720   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,721   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,721   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,722   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,722   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,722   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,723   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,724   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,725   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,726   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,730   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,731   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,732   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,732   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,732   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:26:14,733   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:26:14,806   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:26:14,844   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62330.
2019-02-17 22:26:14,844   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62330
2019-02-17 22:26:14,845   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:26:14,871   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62330, None)
2019-02-17 22:26:14,873   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62330 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62330, None)
2019-02-17 22:26:14,875   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62330, None)
2019-02-17 22:26:14,875   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62330, None)
2019-02-17 22:26:14,982   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:15,125   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:26:15,144   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:26:15,144   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:26:15,152   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:26:15,152   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:15,153   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:26:15,153   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:26:15,155   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:26:15,576   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:26:17,282   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 140.20686 ms
2019-02-17 22:26:17,302   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.966276 ms
2019-02-17 22:26:17,354   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:26:17,358   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:26:17,359   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:26:17,368   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:26:17,375   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:26:17,375   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:26:17,380   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:26:17,382   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:26:17,387   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:26:17,387   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:26:17,388   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-d76eeb0d-5972-4810-a161-eb5fb5c186df
2019-02-17 22:29:44,559   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:29:44,830   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:29:44,886   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:29:44,887   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:29:44,888   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:29:44,888   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:29:44,889   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:29:45,508   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62561.
2019-02-17 22:29:45,527   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:29:45,546   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:29:45,547   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:29:45,547   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:29:45,557   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-67815ac6-535a-42ed-a582-8dbd8b488783
2019-02-17 22:29:45,577   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:29:45,590   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:29:45,663   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @5282ms
2019-02-17 22:29:45,705   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:29:45,715   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @5336ms
2019-02-17 22:29:45,732   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:29:45,732   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:29:45,748   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,748   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,749   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,749   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,750   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,750   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,750   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,752   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,752   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,752   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,753   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,753   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,754   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,754   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,754   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,755   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,755   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,760   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,760   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,761   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,761   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,762   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:29:45,763   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:29:45,840   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:29:45,880   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62575.
2019-02-17 22:29:45,881   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62575
2019-02-17 22:29:45,882   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:29:45,906   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62575, None)
2019-02-17 22:29:45,909   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62575 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62575, None)
2019-02-17 22:29:45,911   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62575, None)
2019-02-17 22:29:45,912   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62575, None)
2019-02-17 22:29:46,026   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:46,195   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:29:46,216   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:29:46,216   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:29:46,227   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:29:46,227   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:46,228   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:29:46,228   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:29:46,230   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:29:46,707   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:29:48,422   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 142.437396 ms
2019-02-17 22:29:48,442   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.943821 ms
2019-02-17 22:29:48,494   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:29:48,499   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:29:48,500   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:29:48,510   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:29:48,518   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:29:48,518   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:29:48,523   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:29:48,526   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:29:48,530   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:29:48,531   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:29:48,531   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-6c36cf72-5110-49de-905c-5a847d570feb
2019-02-17 22:30:17,003   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:30:17,268   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:30:17,320   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:30:17,322   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:30:17,322   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:30:17,322   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:30:17,323   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:30:17,932   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62620.
2019-02-17 22:30:17,950   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:30:17,966   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:30:17,968   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:30:17,968   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:30:17,977   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-d9e95e1c-1340-4368-91dd-8d4394d8eb81
2019-02-17 22:30:17,997   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:30:18,008   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:30:18,077   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2219ms
2019-02-17 22:30:18,118   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:30:18,128   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2270ms
2019-02-17 22:30:18,144   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:30:18,144   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:30:18,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,159   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,160   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,161   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,162   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,162   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,163   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,164   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,165   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,166   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,167   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,172   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,172   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,173   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,173   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,174   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,175   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:30:18,248   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:30:18,287   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62633.
2019-02-17 22:30:18,287   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62633
2019-02-17 22:30:18,289   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:30:18,314   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62633, None)
2019-02-17 22:30:18,317   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62633 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62633, None)
2019-02-17 22:30:18,319   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62633, None)
2019-02-17 22:30:18,319   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62633, None)
2019-02-17 22:30:18,426   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,570   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:30:18,588   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:30:18,588   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:30:18,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,596   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,597   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:18,598   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:30:19,010   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:30:20,701   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 144.871001 ms
2019-02-17 22:30:20,730   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.692312 ms
2019-02-17 22:30:20,780   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:30:20,785   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:30:20,786   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:30:20,794   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:30:20,801   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:30:20,801   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:30:20,805   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:30:20,808   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:30:20,812   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:30:20,812   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:30:20,813   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-04ede796-e503-4cfd-9d1a-52a085a4c61f
2019-02-17 22:30:30,882   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:30:31,147   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:30:31,199   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:30:31,200   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:30:31,201   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:30:31,201   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:30:31,202   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:30:31,809   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62649.
2019-02-17 22:30:31,828   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:30:31,844   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:30:31,846   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:30:31,846   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:30:31,855   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-8408dc6a-00ae-417b-ab13-fc18bcc0fd0c
2019-02-17 22:30:31,875   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:30:31,887   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:30:31,958   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2265ms
2019-02-17 22:30:31,998   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:30:32,008   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2315ms
2019-02-17 22:30:32,023   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:30:32,023   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:30:32,038   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,039   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,039   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,041   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,041   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,042   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,042   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,043   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,043   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,043   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,045   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,045   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,045   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,050   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,050   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,051   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,051   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,052   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,053   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:30:32,125   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:30:32,163   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62662.
2019-02-17 22:30:32,163   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62662
2019-02-17 22:30:32,164   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:30:32,188   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62662, None)
2019-02-17 22:30:32,191   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62662 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62662, None)
2019-02-17 22:30:32,193   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62662, None)
2019-02-17 22:30:32,193   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62662, None)
2019-02-17 22:30:32,302   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,451   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:30:32,470   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:30:32,471   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:30:32,479   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,479   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,480   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,480   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,481   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:30:32,898   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:30:34,623   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 144.429257 ms
2019-02-17 22:30:34,645   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 6.4956 ms
2019-02-17 22:30:34,698   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:30:34,702   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:30:34,703   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:30:34,712   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:30:34,719   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:30:34,719   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:30:34,723   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:30:34,726   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:30:34,730   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:30:34,731   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:30:34,731   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-347d7ce5-c318-4355-8809-b2b93e15d577
2019-02-17 22:32:15,558   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:32:15,823   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:32:15,875   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:32:15,877   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:32:15,877   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:32:15,878   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:32:15,878   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:32:16,516   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62828.
2019-02-17 22:32:16,534   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:32:16,550   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:32:16,552   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:32:16,553   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:32:16,562   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-ac16c7dc-7819-41f8-8157-22730ef99d83
2019-02-17 22:32:16,581   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:32:16,592   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:32:16,662   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2227ms
2019-02-17 22:32:16,703   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:32:16,713   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2278ms
2019-02-17 22:32:16,728   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:32:16,728   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:32:16,745   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,746   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,746   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,746   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,747   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,747   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,747   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,748   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,748   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,749   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,749   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,749   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,750   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,750   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,750   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,751   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,752   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,752   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,757   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,758   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,758   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,759   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,759   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:32:16,760   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:32:16,832   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:32:16,871   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62841.
2019-02-17 22:32:16,872   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62841
2019-02-17 22:32:16,873   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:32:16,896   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62841, None)
2019-02-17 22:32:16,899   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62841 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62841, None)
2019-02-17 22:32:16,901   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62841, None)
2019-02-17 22:32:16,901   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62841, None)
2019-02-17 22:32:17,009   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:17,150   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:32:17,169   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:32:17,169   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:32:17,177   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:32:17,177   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:17,178   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:32:17,178   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:32:17,179   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:32:17,605   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:32:19,292   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 138.635571 ms
2019-02-17 22:32:19,311   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.833144 ms
2019-02-17 22:32:19,330   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:32:19,335   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:32:19,335   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:32:19,344   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:32:19,353   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:32:19,353   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:32:19,358   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:32:19,360   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:32:19,365   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:32:19,365   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:32:19,365   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-02681afa-9a38-40cf-85d0-a446e7134e10
2019-02-17 22:33:01,695   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:33:01,960   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:33:02,012   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:33:02,014   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:33:02,014   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:33:02,014   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:33:02,015   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:33:02,629   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62872.
2019-02-17 22:33:02,647   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:33:02,663   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:33:02,665   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:33:02,666   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:33:02,675   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-b578b9c2-dd8a-457e-964a-41150f2655c2
2019-02-17 22:33:02,694   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:33:02,706   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:33:02,778   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @5216ms
2019-02-17 22:33:02,819   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:33:02,828   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @5267ms
2019-02-17 22:33:02,844   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@63cc6ebb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:33:02,844   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:33:02,859   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@42a9e5d1{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,859   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e8f7922{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,860   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,860   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@58e6d4b8{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,860   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,861   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,861   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,862   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@38f57b3d{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,862   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,862   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,863   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,863   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,863   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,864   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,864   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,864   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,865   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,865   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,865   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,866   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,871   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/static,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,871   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@24bdb479{/,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,872   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/api,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,873   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@67389cb8{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,874   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:33:02,875   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:33:02,949   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:33:02,987   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62885.
2019-02-17 22:33:02,988   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62885
2019-02-17 22:33:02,989   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:33:03,012   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62885, None)
2019-02-17 22:33:03,015   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62885 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62885, None)
2019-02-17 22:33:03,017   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62885, None)
2019-02-17 22:33:03,017   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62885, None)
2019-02-17 22:33:03,126   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@d4ab71a{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:03,274   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:33:03,293   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:33:03,293   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:33:03,300   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1144a55a{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:33:03,301   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:03,301   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3cc20577{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:33:03,302   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:03,303   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2228db21{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:33:03,718   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:33:05,365   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 136.812132 ms
2019-02-17 22:33:05,385   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.882227 ms
2019-02-17 22:33:05,404   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:33:05,408   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@63cc6ebb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:33:05,409   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:33:05,420   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:33:05,428   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:33:05,428   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:33:05,433   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:33:05,435   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:33:05,440   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:33:05,440   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:33:05,440   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-fdd4ee55-696e-4351-84f2-c6115ff18d4a
2019-02-17 22:33:38,421   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:33:38,680   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:33:38,733   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:33:38,735   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:33:38,735   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:33:38,736   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:33:38,736   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:33:39,350   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62917.
2019-02-17 22:33:39,368   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:33:39,386   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:33:39,388   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:33:39,389   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:33:39,398   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-78bc8058-a5aa-4123-ad16-d6390544a05b
2019-02-17 22:33:39,419   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:33:39,430   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:33:39,499   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2172ms
2019-02-17 22:33:39,544   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:33:39,555   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2229ms
2019-02-17 22:33:39,571   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:33:39,571   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:33:39,587   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,588   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,589   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,589   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,589   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,590   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,590   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,590   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,591   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,591   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,592   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,593   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,594   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,599   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,600   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,601   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,601   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,602   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:33:39,603   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:33:39,681   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:33:39,730   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62930.
2019-02-17 22:33:39,731   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62930
2019-02-17 22:33:39,732   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:33:39,750   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62930, None)
2019-02-17 22:33:39,753   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62930 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62930, None)
2019-02-17 22:33:39,755   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62930, None)
2019-02-17 22:33:39,755   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62930, None)
2019-02-17 22:33:39,867   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:40,000   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:33:40,020   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:33:40,020   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:33:40,037   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:33:40,038   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:40,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:33:40,042   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:33:40,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:33:40,532   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:33:42,264   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 147.28279 ms
2019-02-17 22:33:42,285   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 6.06765 ms
2019-02-17 22:33:42,350   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:33:42,353   INFO --- [Spark Context Cleaner]  org.apache.spark.ContextCleaner(line:54) : Cleaned accumulator 0
2019-02-17 22:33:42,356   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:33:42,357   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:33:42,365   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:33:42,373   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:33:42,373   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:33:42,377   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:33:42,380   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:33:42,385   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:33:42,385   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:33:42,385   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-21792bce-766e-4f29-9112-9fb575f8d2cf
2019-02-17 22:34:10,088   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:34:10,361   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:34:10,412   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:34:10,414   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:34:10,414   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:34:10,415   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:34:10,415   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:34:11,018   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 62959.
2019-02-17 22:34:11,035   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:34:11,052   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:34:11,053   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:34:11,054   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:34:11,063   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-ff1c71e8-929b-4952-beee-405d23850f3d
2019-02-17 22:34:11,083   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:34:11,095   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:34:11,166   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2159ms
2019-02-17 22:34:11,211   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:34:11,222   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2216ms
2019-02-17 22:34:11,238   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:34:11,239   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:34:11,254   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,254   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,255   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,255   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,256   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,256   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,256   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,257   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,257   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,258   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,258   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,258   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,259   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,259   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,259   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,260   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,260   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,261   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,261   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,261   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,266   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,266   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,267   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,268   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,268   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,269   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:34:11,342   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:34:11,381   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62972.
2019-02-17 22:34:11,381   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:62972
2019-02-17 22:34:11,382   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:34:11,406   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 62972, None)
2019-02-17 22:34:11,409   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:62972 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 62972, None)
2019-02-17 22:34:11,411   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 62972, None)
2019-02-17 22:34:11,411   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 62972, None)
2019-02-17 22:34:11,519   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,658   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:34:11,676   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:34:11,676   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:34:11,684   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,685   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,685   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,685   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:34:11,687   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:34:12,097   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:34:13,800   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 138.908894 ms
2019-02-17 22:34:13,819   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.5996 ms
2019-02-17 22:34:13,909   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:34:13,914   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:34:13,915   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:34:13,923   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:34:13,930   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:34:13,930   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:34:13,935   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:34:13,937   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:34:13,942   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:34:13,942   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:34:13,943   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-9bb80f6c-ef00-441d-9b5c-89283bc1ba26
2019-02-17 22:35:29,776   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:35:30,060   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:35:30,115   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:35:30,117   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:35:30,118   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:35:30,118   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:35:30,118   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:35:30,783   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 63046.
2019-02-17 22:35:30,802   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:35:30,820   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:35:30,822   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:35:30,822   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:35:30,832   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-a0022fc4-8dde-48dd-b757-e1420157be36
2019-02-17 22:35:30,855   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:35:30,868   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:35:30,939   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2331ms
2019-02-17 22:35:30,986   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:35:30,997   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2391ms
2019-02-17 22:35:31,015   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:35:31,015   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:35:31,032   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,032   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,033   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,033   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,034   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,034   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,034   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,035   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,035   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,036   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,036   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,037   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,038   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,038   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,038   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,039   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,039   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,046   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,046   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,047   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,048   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,048   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,049   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:35:31,131   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:35:31,170   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63059.
2019-02-17 22:35:31,171   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:63059
2019-02-17 22:35:31,172   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:35:31,197   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 63059, None)
2019-02-17 22:35:31,200   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:63059 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 63059, None)
2019-02-17 22:35:31,202   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 63059, None)
2019-02-17 22:35:31,202   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 63059, None)
2019-02-17 22:35:31,314   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,461   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:35:31,479   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:35:31,480   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:35:31,488   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,488   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,489   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,489   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,490   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:35:31,935   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:35:33,652   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 147.829117 ms
2019-02-17 22:35:33,674   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 6.354447 ms
2019-02-17 22:35:33,703   INFO --- [Spark Context Cleaner]  org.apache.spark.ContextCleaner(line:54) : Cleaned accumulator 0
2019-02-17 22:35:33,774   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:35:33,780   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:35:33,781   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:35:33,789   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:35:33,796   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:35:33,796   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:35:33,801   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:35:33,803   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:35:33,808   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:35:33,808   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:35:33,809   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-80d1e24d-f7dd-490e-b21f-152367193f82
2019-02-17 22:36:27,849   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:36:28,113   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:36:28,165   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:36:28,167   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:36:28,167   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:36:28,168   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:36:28,168   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:36:28,764   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 63144.
2019-02-17 22:36:28,783   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:36:28,799   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:36:28,801   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:36:28,802   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:36:28,811   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-ca7d793c-abf1-4a1d-b242-bb36cad50c50
2019-02-17 22:36:28,832   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:36:28,843   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:36:28,913   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2175ms
2019-02-17 22:36:28,954   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:36:28,963   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2226ms
2019-02-17 22:36:28,979   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:36:28,979   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:36:28,994   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,994   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,995   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,995   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,996   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,997   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,997   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,998   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:28,999   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,000   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,000   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,000   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,001   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,001   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,006   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,006   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,007   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,007   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,008   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,009   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:36:29,083   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:36:29,122   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63157.
2019-02-17 22:36:29,123   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:63157
2019-02-17 22:36:29,124   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:36:29,147   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 63157, None)
2019-02-17 22:36:29,150   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:63157 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 63157, None)
2019-02-17 22:36:29,152   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 63157, None)
2019-02-17 22:36:29,152   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 63157, None)
2019-02-17 22:36:29,260   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,403   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:36:29,421   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:36:29,421   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:36:29,429   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,429   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,430   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,430   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,431   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:36:29,850   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:36:31,531   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 140.672023 ms
2019-02-17 22:36:31,549   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.448182 ms
2019-02-17 22:36:31,591   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:36:31,596   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:36:31,597   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:36:31,605   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:36:31,612   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:36:31,612   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:36:31,617   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:36:31,619   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:36:31,624   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:36:31,624   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:36:31,625   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-1d61de5f-a2f6-4e7d-95b5-bb00a0eb38b9
2019-02-17 22:36:46,885   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:36:47,153   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:36:47,207   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:36:47,209   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:36:47,209   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:36:47,210   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:36:47,210   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:36:47,811   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 63174.
2019-02-17 22:36:47,829   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:36:47,846   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:36:47,848   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:36:47,848   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:36:47,858   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-94418619-6283-485c-a207-b4c674315afc
2019-02-17 22:36:47,877   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:36:47,889   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:36:47,956   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2197ms
2019-02-17 22:36:47,998   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:36:48,007   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2250ms
2019-02-17 22:36:48,023   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:36:48,023   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:36:48,039   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,039   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,040   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,041   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,041   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,041   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,042   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,042   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,043   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,043   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,043   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,044   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,045   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,045   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,046   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,046   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,046   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,051   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,052   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,053   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,053   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,053   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,054   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:36:48,130   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:36:48,170   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63187.
2019-02-17 22:36:48,171   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:63187
2019-02-17 22:36:48,172   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:36:48,197   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 63187, None)
2019-02-17 22:36:48,200   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:63187 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 63187, None)
2019-02-17 22:36:48,202   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 63187, None)
2019-02-17 22:36:48,202   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 63187, None)
2019-02-17 22:36:48,310   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,452   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:36:48,470   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:36:48,470   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:36:48,477   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,477   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,478   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,478   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,479   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:36:48,891   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:36:50,579   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 148.941979 ms
2019-02-17 22:36:50,609   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.537364 ms
2019-02-17 22:36:50,651   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:36:50,656   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:36:50,657   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:36:50,665   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:36:50,683   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:36:50,683   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:36:50,688   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:36:50,691   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:36:50,696   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:36:50,696   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:36:50,696   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-a61528d5-81b9-4e21-bb4b-fe343528e1fe
2019-02-17 22:37:34,313   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:37:34,607   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:37:34,663   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:37:34,665   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:37:34,665   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:37:34,666   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:37:34,666   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:37:35,286   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 63218.
2019-02-17 22:37:35,304   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:37:35,320   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:37:35,322   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:37:35,323   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:37:35,332   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-e0985fcb-8a9f-4416-a297-be921a0ae72c
2019-02-17 22:37:35,352   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:37:35,364   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:37:35,437   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @3335ms
2019-02-17 22:37:35,478   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:37:35,488   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @3386ms
2019-02-17 22:37:35,504   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:37:35,504   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:37:35,519   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,520   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,520   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,521   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,521   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,521   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,522   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,522   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,523   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,523   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,523   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,524   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,524   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,524   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,525   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,525   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,526   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,526   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,526   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,527   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,531   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,532   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,533   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,533   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,533   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,534   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:37:35,610   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:37:35,649   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63231.
2019-02-17 22:37:35,649   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:63231
2019-02-17 22:37:35,650   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:37:35,673   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 63231, None)
2019-02-17 22:37:35,676   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:63231 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 63231, None)
2019-02-17 22:37:35,678   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 63231, None)
2019-02-17 22:37:35,678   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 63231, None)
2019-02-17 22:37:35,786   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,932   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:37:35,950   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:37:35,950   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:37:35,957   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,958   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,958   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,959   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:37:35,960   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:37:36,383   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:37:38,093   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 139.76287 ms
2019-02-17 22:37:38,113   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.807479 ms
2019-02-17 22:37:38,157   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:37:38,161   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:37:38,162   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:37:38,171   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:37:38,178   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:37:38,178   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:37:38,183   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:37:38,185   INFO --- [dispatcher-event-loop-1]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:37:38,190   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:37:38,190   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:37:38,191   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-44113cdf-0d25-4123-8570-0b86f0579679
2019-02-17 22:38:11,545   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Running Spark version 2.4.0
2019-02-17 22:38:11,808   INFO --- [main]  org.apache.spark.SparkContext(line:54) : Submitted application: sql
2019-02-17 22:38:11,862   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls to: Administrator
2019-02-17 22:38:11,864   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls to: Administrator
2019-02-17 22:38:11,864   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing view acls groups to: 
2019-02-17 22:38:11,864   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : Changing modify acls groups to: 
2019-02-17 22:38:11,865   INFO --- [main]  org.apache.spark.SecurityManager(line:54) : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2019-02-17 22:38:12,466   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'sparkDriver' on port 63256.
2019-02-17 22:38:12,484   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering MapOutputTracker
2019-02-17 22:38:12,500   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering BlockManagerMaster
2019-02-17 22:38:12,502   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-02-17 22:38:12,502   INFO --- [main]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : BlockManagerMasterEndpoint up
2019-02-17 22:38:12,511   INFO --- [main]  org.apache.spark.storage.DiskBlockManager(line:54) : Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-fcd6cb28-666b-46ed-b08e-fe44504d4b1e
2019-02-17 22:38:12,531   INFO --- [main]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore started with capacity 1044.5 MB
2019-02-17 22:38:12,542   INFO --- [main]  org.apache.spark.SparkEnv(line:54) : Registering OutputCommitCoordinator
2019-02-17 22:38:12,612   INFO --- [main]  org.spark_project.jetty.util.log(line:192) : Logging initialized @2203ms
2019-02-17 22:38:12,653   INFO --- [main]  org.spark_project.jetty.server.Server(line:351) : jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-02-17 22:38:12,663   INFO --- [main]  org.spark_project.jetty.server.Server(line:419) : Started @2254ms
2019-02-17 22:38:12,678   INFO --- [main]  org.spark_project.jetty.server.AbstractConnector(line:278) : Started ServerConnector@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:38:12,678   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'SparkUI' on port 4040.
2019-02-17 22:38:12,694   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@5b080f3a{/jobs,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,694   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@63192798{/jobs/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,694   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@50eca7c6{/jobs/job,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,695   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@1de5f0ef{/jobs/job/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,695   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@376a312c{/stages,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,695   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@28d6290{/stages/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,696   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6ca0256d{/stages/stage,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,696   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@51850751{/stages/stage/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,697   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3ce3db41{/stages/pool,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,697   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@64df9a61{/stages/pool/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,697   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@77602954{/storage,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,698   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@e260766{/storage/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,698   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2c3dec30{/storage/rdd,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,698   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34a97744{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,699   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@4275c20c{/environment,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,699   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7c56e013{/environment/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,700   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3fc9dfc5{/executors,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,700   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@40258c2f{/executors/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,700   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@2cac4385{/executors/threadDump,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,701   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@6731787b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,705   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@16f7b4af{/static,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,705   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@7e3f95fe{/,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,706   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@34625ccd{/api,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,706   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@419a20a6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,707   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@533377b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-02-17 22:38:12,708   INFO --- [main]  org.apache.spark.ui.SparkUI(line:54) : Bound SparkUI to 0.0.0.0, and started at http://192.168.1.2:4040
2019-02-17 22:38:12,781   INFO --- [main]  org.apache.spark.executor.Executor(line:54) : Starting executor ID driver on host localhost
2019-02-17 22:38:12,818   INFO --- [main]  org.apache.spark.util.Utils(line:54) : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63269.
2019-02-17 22:38:12,819   INFO --- [main]  org.apache.spark.network.netty.NettyBlockTransferService(line:54) : Server created on 192.168.1.2:63269
2019-02-17 22:38:12,820   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-02-17 22:38:12,844   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registering BlockManager BlockManagerId(driver, 192.168.1.2, 63269, None)
2019-02-17 22:38:12,846   INFO --- [dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerMasterEndpoint(line:54) : Registering block manager 192.168.1.2:63269 with 1044.5 MB RAM, BlockManagerId(driver, 192.168.1.2, 63269, None)
2019-02-17 22:38:12,848   INFO --- [main]  org.apache.spark.storage.BlockManagerMaster(line:54) : Registered BlockManager BlockManagerId(driver, 192.168.1.2, 63269, None)
2019-02-17 22:38:12,849   INFO --- [main]  org.apache.spark.storage.BlockManager(line:54) : Initialized BlockManager: BlockManagerId(driver, 192.168.1.2, 63269, None)
2019-02-17 22:38:12,955   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3b4ef7{/metrics/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:13,102   WARN --- [main]  org.apache.spark.SparkContext(line:66) : Using an existing SparkContext; some configuration may not take effect.
2019-02-17 22:38:13,121   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/').
2019-02-17 22:38:13,121   INFO --- [main]  org.apache.spark.sql.internal.SharedState(line:54) : Warehouse path is 'file:/C:/Users/Administrator/IdeaProjects/spark-vlearn/spark-warehouse/'.
2019-02-17 22:38:13,130   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@3e521715{/SQL,null,AVAILABLE,@Spark}
2019-02-17 22:38:13,131   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@26a529dc{/SQL/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:13,131   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@33a630fa{/SQL/execution,null,AVAILABLE,@Spark}
2019-02-17 22:38:13,132   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@775594f2{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-02-17 22:38:13,133   INFO --- [main]  org.spark_project.jetty.server.handler.ContextHandler(line:781) : Started o.s.j.s.ServletContextHandler@48b0e701{/static/sql,null,AVAILABLE,@Spark}
2019-02-17 22:38:13,543   INFO --- [main]  org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef(line:54) : Registered StateStoreCoordinator endpoint
2019-02-17 22:38:15,185   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 139.615301 ms
2019-02-17 22:38:15,205   INFO --- [main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator(line:54) : Code generated in 5.77957 ms
2019-02-17 22:38:15,247   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Invoking stop() from shutdown hook
2019-02-17 22:38:15,252   INFO --- [Thread-1]  org.spark_project.jetty.server.AbstractConnector(line:318) : Stopped Spark@b968a76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-02-17 22:38:15,253   INFO --- [Thread-1]  org.apache.spark.ui.SparkUI(line:54) : Stopped Spark web UI at http://192.168.1.2:4040
2019-02-17 22:38:15,261   INFO --- [dispatcher-event-loop-1]  org.apache.spark.MapOutputTrackerMasterEndpoint(line:54) : MapOutputTrackerMasterEndpoint stopped!
2019-02-17 22:38:15,268   INFO --- [Thread-1]  org.apache.spark.storage.memory.MemoryStore(line:54) : MemoryStore cleared
2019-02-17 22:38:15,268   INFO --- [Thread-1]  org.apache.spark.storage.BlockManager(line:54) : BlockManager stopped
2019-02-17 22:38:15,273   INFO --- [Thread-1]  org.apache.spark.storage.BlockManagerMaster(line:54) : BlockManagerMaster stopped
2019-02-17 22:38:15,275   INFO --- [dispatcher-event-loop-0]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:54) : OutputCommitCoordinator stopped!
2019-02-17 22:38:15,280   INFO --- [Thread-1]  org.apache.spark.SparkContext(line:54) : Successfully stopped SparkContext
2019-02-17 22:38:15,280   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Shutdown hook called
2019-02-17 22:38:15,281   INFO --- [Thread-1]  org.apache.spark.util.ShutdownHookManager(line:54) : Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-8a3b4ff9-28af-48f6-bfc4-dd6002fc0190
